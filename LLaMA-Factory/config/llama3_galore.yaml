### model
model_name_or_path: /root/autodl-tmp/models/LLM-Research/Meta-Llama-3-8B-Instruct
trust_remote_code: true

### method
stage: sft
do_train: true
finetuning_type: full
use_galore: true
galore_layerwise: true     # 【关键】官方示例的核心，逐层更新，极大节省显存
galore_target: all
galore_rank: 16           # 既然开了 layerwise，128 是可以跑的
galore_scale: 2.0          # 遵循官方示例设为 2.0

### dataset
dataset: identity          # 先用 identity 跑通测试
template: llama3
cutoff_len: 2048
max_samples: 1000
overwrite_cache: true
preprocessing_num_workers: 16
dataloader_num_workers: 4

### output
output_dir: saves/llama3-8b/galore/sft  # 修改路径以防覆盖
logging_steps: 10
save_steps: 500
plot_loss: true
overwrite_output_dir: true
save_only_model: false
report_to: none

### train
per_device_train_batch_size: 1  # 【建议】显存够的话尝试设为 2，因为下面必须是 1
gradient_accumulation_steps: 1  # 【严格遵循】官方注释说 layerwise 必须设为 1
learning_rate: 1.0e-5
num_train_epochs: 3.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
pure_bf16: true            # 4090 必开，节省显存
ddp_timeout: 180000000
optim: adamw_torch
gradient_checkpointing: true
### 显存优化 (可选，为了保险起见建议加上)
# optim: adamw_8bit        # 如果 layerwise 依然爆显存，请取消注释这一行